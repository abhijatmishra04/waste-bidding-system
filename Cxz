package com.bofa.sst.batch.core.impl;

import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import org.apache.commons.lang3.StringUtils;
import org.springframework.batch.core.ExecutionContext;
import org.springframework.batch.core.StepExecution;
import org.springframework.batch.core.annotation.AfterStep;
import org.springframework.batch.core.annotation.BeforeStep;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.stereotype.Component;

import com.bofa.sst.batch.model.CustaggProcessedRecordsDTO;
import com.bofa.sst.batch.model.CustaggRecordsDTO;

import lombok.extern.log4j.Log4j2;

/**
 * Enriches raw {@link CustaggRecordsDTO} with alpha-entity, performs a
 * *job-wide* deduplication on <code>productCode#numericEntity#accountNumber</code>,
 * and emits {@link CustaggProcessedRecordsDTO}.
 */
@Log4j2
@Component
public class CustaggProcessor
        implements ItemProcessor<CustaggRecordsDTO, CustaggProcessedRecordsDTO> {

    /** Injected by validation tasklet and restored in {@link #beforeStep}. */
    private Map<String, String> entityMap;

    /** Job-wide cache to detect duplicates across all partitions. */
    private ConcurrentMap<String, Boolean> dedupCache;

    /** Per-step counter so we can aggregate later in a JobListener. */
    private long dupSkipped = 0;

    // ------------------------------- lifecycle hooks -------------------------

    /**
     * Initialise caches before the chunk processing starts.
     */
    @SuppressWarnings("unchecked")
    @BeforeStep
    public void beforeStep(StepExecution stepExecution) {
        ExecutionContext jobCtx = stepExecution.getJobExecution().getExecutionContext();

        entityMap = (Map<String, String>) jobCtx.get("entityMap");
        if (entityMap == null) {
            throw new IllegalStateException("entityMap missing from JobExecutionContext");
        }

        dedupCache = (ConcurrentMap<String, Boolean>) jobCtx.get("dedupCache");
        if (dedupCache == null) {
            dedupCache = new ConcurrentHashMap<>(1_000_000);
            jobCtx.put("dedupCache", dedupCache);
        }

        log.info("CustaggProcessor initialised - entityMap size = {}, dedupCache size = {}",
                 entityMap.size(), dedupCache.size());
    }

    // -------------------------------- processing -----------------------------

    /**
     * 1. Map numeric → alpha entity (skip if not found).  
     * 2. Deduplicate on productCode#numericEntity#accountNumber (skip dupes).  
     * 3. Emit enriched DTO.
     */
    @Override
    public CustaggProcessedRecordsDTO process(CustaggRecordsDTO record) {
        // Defensive null-check for the whole record
        if (record == null) {
            log.warn("Skipping null record");          // should never happen
            return null;
        }

        try {
            /* ---------- 1. entity mapping ---------- */
            String alpha = entityMap.get(record.getEntity());
            if (alpha == null) {
                log.debug("Skipping – no alpha mapping for numericEntity={}", record.getEntity());
                return null;                           // filtered out, not an error
            }

            /* ---------- 2. global dedup ---------- */
            String key = new StringBuilder()
                            .append(record.getProductCode()).append('#')
                            .append(record.getEntity()).append('#')
                            .append(record.getAccountNumber())
                            .toString();

            if (dedupCache.putIfAbsent(key, Boolean.TRUE) != null) {
                dupSkipped++;
                log.debug("Duplicate skipped – key={}", key);
                return null;                           // filtered out, not an error
            }

            /* ---------- 3. emit enriched DTO ---------- */
            return new CustaggProcessedRecordsDTO(
                    record.getAccountNumber(),
                    record.getEntity(),
                    alpha,
                    record.getProductCode()
            );

        } catch (Exception ex) {
            // Capture + re-throw so Spring Batch can mark the item as failed
            log.error("Processing failed for record={}, reason={}", record, ex.toString(), ex);
            throw ex;                                  // keeps stack-trace intact
        }
    }

    // ------------------------------- tear-down --------------------------------

    /**
     * Persist per-step metrics for job-level aggregation.
     */
    @AfterStep
    public void afterStep(StepExecution stepExecution) {
        ExecutionContext stepCtx = stepExecution.getExecutionContext();
        stepCtx.putLong("dupSkipped", dupSkipped);

        log.info("Step '{}' completed – duplicates skipped = {}",
                 stepExecution.getStepName(), dupSkipped);
    }
}
