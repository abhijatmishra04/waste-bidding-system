#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Locust metrics worker:
Reads logs/latency_feed.jsonl (JSONL, one record per call) and updates a Locust
statistics engine. Periodically writes aggregated metrics to logs/locust_metrics.jsonl.
"""

import os
import time
import json
import logging
from logging.handlers import RotatingFileHandler

# Disable any monkey patching for compatibility with SSRAI
os.environ.setdefault("LOCUST_NO_MONKEY_PATCH", "1")
from locust.env import Environment

FEED = "logs/latency_feed.jsonl"
OUT = "logs/locust_metrics.jsonl"
OFFSET = "logs/locust_feed.offset"
SNAP_INTERVAL_SECS = 5


def _setup_logger(path: str) -> logging.Logger:
    """Initialize rotating file and console logger."""
    logger = logging.getLogger("locust.metrics")
    logger.setLevel(logging.INFO)
    logger.propagate = False

    if not logger.handlers:
        os.makedirs(os.path.dirname(os.path.abspath(path)), exist_ok=True)
        file_handler = RotatingFileHandler(path, maxBytes=10 * 1024 * 1024, backupCount=3)
        file_handler.setFormatter(logging.Formatter("%(message)s"))
        logger.addHandler(file_handler)

        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter("%(message)s"))
        logger.addHandler(console_handler)

    return logger


def _read_checkpoint() -> int:
    """Read last processed byte offset from checkpoint file."""
    try:
        with open(OFFSET, "r", encoding="utf-8") as f:
            return int(f.read().strip() or "0")
    except Exception:
        return 0


def _write_checkpoint(offset: int):
    """Write current byte offset to checkpoint file."""
    os.makedirs(os.path.dirname(os.path.abspath(OFFSET)), exist_ok=True)
    with open(OFFSET, "w", encoding="utf-8") as f:
        f.write(str(offset))


def _snapshot(env: Environment) -> dict:
    """Capture a snapshot of Locust's current metrics."""
    stats = env.stats
    total = stats.total
    snapshot = {
        "ts": time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime()),
        "locust_num_requests": total.num_requests,
        "locust_num_failures": total.num_failures,
        "locust_success_rate_pct": round(
            ((total.num_requests - total.num_failures) / total.num_requests * 100.0)
            if total.num_requests
            else 0.0,
            2,
        ),
        "locust_avg_latency_ms": round(getattr(total, "avg_response_time", 0.0), 2),
        "locust_p50_latency_ms": round(total.get_current_response_time_percentile(0.50) or 0.0, 2),
        "locust_p95_latency_ms": round(total.get_current_response_time_percentile(0.95) or 0.0, 2),
        "current_rps": round(getattr(total, "current_rps", 0.0), 2),
    }

    # Per-model metrics
    for (method, name), entry in list(stats.entries.items()):
        if method != "RAI":
            continue
        snapshot[f"model::{name}"] = {
            "num_requests": entry.num_requests,
            "num_failures": entry.num_failures,
            "avg_ms": round(entry.avg_response_time, 2),
            "p50_ms": round(entry.get_current_response_time_percentile(0.50) or 0.0, 2),
            "p95_ms": round(entry.get_current_response_time_percentile(0.95) or 0.0, 2),
        }
    return snapshot


def main():
    logger = _setup_logger(OUT)
    env = Environment(user_classes=[])

    # Display file paths in use
    print("[Locust worker] FEED  :", os.path.abspath(FEED))
    print("[Locust worker] OUT   :", os.path.abspath(OUT))
    print("[Locust worker] OFFSET:", os.path.abspath(OFFSET))

    # Open feed file and resume from last processed offset
    os.makedirs(os.path.dirname(os.path.abspath(FEED)), exist_ok=True)
    f = open(FEED, "a+", encoding="utf-8")
    f.seek(0, os.SEEK_END)
    size = f.tell()
    offset = _read_checkpoint()
    if offset > size:
        offset = 0
    f.seek(offset)

    # Write initial snapshot (even if empty)
    logger.info(json.dumps(_snapshot(env), ensure_ascii=False))

    last_snap = time.time()

    try:
        while True:
            line = f.readline()
            if not line:
                time.sleep(0.25)
            else:
                offset = f.tell()
                try:
                    record = json.loads(line)
                    model = str(record.get("model") or "UNKNOWN")
                    ok = bool(record.get("ok"))
                    latency = int(record.get("latency_ms") or 0)

                    # Log request/failure into Locust stats
                    if ok:
                        env.stats.log_request("RAI", model, latency, response_length=0)
                    else:
                        env.stats.log_error("RAI", model, RuntimeError(record.get("error") or "error"))

                except Exception as ex:
                    print("Error processing feed line:", ex)

            # Periodically write a metrics snapshot
            if (time.time() - last_snap) >= SNAP_INTERVAL_SECS:
                last_snap = time.time()
                snapshot = _snapshot(env)
                logger.info(json.dumps(snapshot, ensure_ascii=False))
                _write_checkpoint(offset)

    except KeyboardInterrupt:
        _write_checkpoint(offset)
        f.close()


if __name__ == "__main__":
    main()
