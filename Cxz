
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
PDF -> PNG -> LLM (via RAI) KV extractor with:
- Detailed logging
- Image payload that matches your working code: {"type":"image_url","image_url":{"url":"data:image/png;base64,..."}}
- Robust TEXT-only fallback if image calls fail (no regex; LLM still extracts)
- Route preflight that tolerates various return types from model.search()
- Optional guardrail profile and forced image payload format

Windows CMD example:

  python pdf_to_json_agent_langchain.py ^
    --cfg ".\config\rai_config.cfg" ^
    --model "azure-openai.gpt-4o" ^
    --pdf ".\docs\sample-invoice.pdf" ^
    --out ".\outputs\sample-invoice.kv.json" ^
    --log-level DEBUG --dump-images ".\debug\pngs" --text-fallback
"""

import os
import re
import json
import time
import base64
import shutil
import argparse
import logging
import tempfile
from typing import List, Optional, OrderedDict as TOrderedDict
from collections import OrderedDict

# ---------- PDF rendering ----------
try:
    import fitz  # PyMuPDF
    _HAVE_FITZ = True
except Exception:
    _HAVE_FITZ = False

import pdfplumber  # also used for TEXT fallback

# ---------- Pydantic v2 ----------
from pydantic import BaseModel, Field, field_validator

# ---------- LangChain Core ----------
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.runnables import RunnableLambda

# ---------- RAI SDK ----------
from ssrai import SSRAIClient


# ======================== Data models ========================

class KV(BaseModel):
    key: str = Field(..., description="Field name (normalized)")
    value: str = Field(..., description="Extracted value as plain text")
    page: int = Field(..., ge=1, description="1-based page number")
    confidence: float = Field(..., ge=0, le=1, description="0..1 model confidence")

    @field_validator("key")
    @classmethod
    def _strip_key(cls, v: str) -> str:
        return v.strip()


class ExtractedDoc(BaseModel):
    items: List[KV] = Field(default_factory=list)


# ======================== Logging ========================

def setup_logger(level: str, log_file: Optional[str]) -> logging.Logger:
    lvl = getattr(logging, (level or "INFO").upper(), logging.INFO)
    logger = logging.getLogger("pdf2json")
    logger.setLevel(lvl)
    logger.handlers.clear()

    fmt = logging.Formatter(
        "%(asctime)s | %(levelname)-8s | %(name)s | %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )

    ch = logging.StreamHandler()
    ch.setLevel(lvl)
    ch.setFormatter(fmt)
    logger.addHandler(ch)

    if log_file:
        os.makedirs(os.path.dirname(log_file) or ".", exist_ok=True)
        fh = logging.FileHandler(log_file, encoding="utf-8")
        fh.setLevel(lvl)
        fh.setFormatter(fmt)
        logger.addHandler(fh)

    if lvl > logging.DEBUG:
        logging.getLogger("urllib3.connectionpool").setLevel(logging.WARNING)
        logging.getLogger("ssrai").setLevel(logging.INFO)
        logging.getLogger("pdfplumber").setLevel(logging.WARNING)

    return logger


# ======================== Agent ========================

class PDF2JSON:
    def __init__(
        self,
        cfg: str,
        model: str,
        *,
        temperature: float = 0.0,
        max_tokens: int = 1300,
        allowed_keys: Optional[List[str]] = None,
        max_pages: int = 10,
        dpi: int = 200,
        dump_images: Optional[str] = None,
        keep_images: bool = False,
        logger: Optional[logging.Logger] = None,
        text_fallback: bool = True,
        page_chunk_chars: int = 12000,
        force_format: Optional[str] = None,  # kept for CLI parity
        profile: Optional[str] = None,
    ):
        # RAI client (use profile only if provided)
        self.cli = SSRAIClient(config_file=cfg, profile=profile) if profile else SSRAIClient(config_file=cfg)
        self.model = model

        # settings
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.allowed_keys = allowed_keys or []
        self.max_pages = max_pages
        self.dpi = dpi
        self.dump_images = dump_images
        self.keep_images = keep_images
        self.text_fallback = text_fallback
        self.page_chunk_chars = page_chunk_chars
        self.force_format = force_format  # not needed anymore, but we keep the switch

        # logging
        self.log = logger or logging.getLogger("pdf2json")

        # parser + prompts
        self.parser = PydanticOutputParser(pydantic_object=ExtractedDoc)
        self.allowed_block = (
            "Only output keys from this list:\n- " + "\n- ".join(self.allowed_keys) + "\n"
            if self.allowed_keys else
            "Output any clearly labeled field names as keys.\n"
        )
        prompt_t = r"""
You are a precise information-extraction engine.
Given attached INVOICE PAGE IMAGES (PNG) or plain TEXT, extract explicit **key-value** pairs.

Rules:
- {{ allowed_keys_block }}
- Keep values verbatim; normalize whitespace only.
- If a field repeats across pages, still return it (we will dedupe later).
- If nothing certain is present, return {"items": []}.
- Estimate confidence between 0 and 1.
- Return **ONLY** valid JSON following the schema.

{{format_instructions}}
""".strip()
        strict_suffix = "\n\nREMINDER: Output JSON ONLY. No markdown, no prose, no comments."

        self.prompt = PromptTemplate(
            template=prompt_t,
            template_format="jinja2",
            input_variables=["allowed_keys_block"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()},
        )
        self.prompt_strict = PromptTemplate(
            template=prompt_t + strict_suffix,
            template_format="jinja2",
            input_variables=["allowed_keys_block"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()},
        )
        self.to_text = RunnableLambda(lambda p: p.to_string() if hasattr(p, "to_string") else str(p))

        # sanitizer
        def _sanitize(text: str) -> str:
            try:
                json.loads(text)
                return text
            except Exception:
                pass
            m = re.search(r"```json\s*(\{.*?\})\s*```", text, flags=re.DOTALL | re.IGNORECASE)
            if m:
                return m.group(1)
            s, e = text.find("{"), text.rfind("}")
            if s != -1 and e != -1 and e > s:
                return text[s:e+1]
            return text

        self.sanitize = RunnableLambda(_sanitize)

    # ---------- normalize model.search() results ----------
    def _iter_model_rows(self):
        """
        Normalize whatever ssrai.model.search() returns into dicts:
        {"modelName": <str>, "features": <any>}
        """
        # hint: pass a query when possible to reduce rows
        try:
            rows = self.cli.model.search(query=self.model)
        except Exception:
            rows = self.cli.model.search()

        # 1) pandas DataFrame
        try:
            import pandas as pd  # noqa
            if hasattr(rows, "to_dict") and hasattr(rows, "columns"):
                cols = [str(c) for c in list(rows.columns)]
                name_col = None
                for c in ("modelName", "name", "model", "route"):
                    if c in cols:
                        name_col = c
                        break
                if name_col is not None:
                    for _, r in rows.iterrows():
                        yield {
                            "modelName": str(r.get(name_col)),
                            "features": r.get("features", {}) if "features" in cols else {},
                        }
                    return
        except Exception:
            pass

        # 2) dict mapping
        if isinstance(rows, dict):
            for k, v in rows.items():
                yield {"modelName": str(k), "features": v}
            return

        # 3) list/tuple
        if isinstance(rows, (list, tuple)):
            for r in rows:
                if isinstance(r, dict):
                    name = r.get("modelName") or r.get("name") or r.get("route") or r.get("model")
                    yield {"modelName": str(name), "features": r.get("features", {})}
                elif isinstance(r, str):
                    yield {"modelName": r, "features": {}}
                elif isinstance(r, (list, tuple)):
                    name = r[0] if r else ""
                    feats = r[1] if len(r) > 1 else {}
                    yield {"modelName": str(name), "features": feats}
                else:
                    yield {"modelName": str(r), "features": {}}
            return

        # 4) single object fallback
        yield {"modelName": str(rows), "features": {}}

    def _validate_model_route(self):
        models = list(self._iter_model_rows())
        names = [m.get("modelName") for m in models]
        self.log.info("Found %d models matching the search criteria.", len(models))

        match = [m for m in models if (m.get("modelName") or "").strip().lower() == self.model.strip().lower()]
        if not match:
            raise ValueError(
                f"Model '{self.model}' not found on the gateway.\n"
                f"Available routes (first 10): {names[:10]} ..."
            )

        feats = (match[0].get("features") or {})
        looks_vision = any(k in str(feats).lower() for k in ["4o", "vision", "image", "multimodal"])
        if not looks_vision:
            self.log.warning(
                "Model '%s' may not be image-enabled (features=%s). "
                "Image path may fail; TEXT fallback is enabled.",
                self.model, feats
            )
        self.log.info("Using model '%s' (features=%s)", self.model, feats)

    # ---------- PDF -> PNG ----------
    def _pdf_to_png_paths(self, pdf_path: str) -> List[str]:
        if self.dump_images:
            out_dir, temp_dir = self.dump_images, None
            os.makedirs(out_dir, exist_ok=True)
        else:
            temp_dir = tempfile.mkdtemp(prefix="pdfpng_")
            out_dir = temp_dir
        self._temp_render_dir = None if self.keep_images or self.dump_images else temp_dir

        paths: List[str] = []
        t0 = time.perf_counter()
        if _HAVE_FITZ:
            self.log.info("Rendering PDF with PyMuPDF @%ddpi (max_pages=%d)...", self.dpi, self.max_pages)
            doc = fitz.open(pdf_path)
            total = min(doc.page_count, self.max_pages)
            self.log.info("PDF has %d pages; rendering %d.", doc.page_count, total)
            for i in range(total):
                page = doc.load_page(i)
                mat = fitz.Matrix(self.dpi / 72.0, self.dpi / 72.0)
                pix = page.get_pixmap(matrix=mat, alpha=False)
                out_path = os.path.join(out_dir, f"page_{i+1:03d}.png")
                pix.save(out_path)
                paths.append(out_path)
                self.log.debug("Rendered page %d -> %s (%dx%d)", i+1, out_path, pix.width, pix.height)
            doc.close()
        else:
            self.log.info("Rendering PDF with pdfplumber @%ddpi (max_pages=%d)...", self.dpi, self.max_pages)
            with pdfplumber.open(pdf_path) as pdf:
                total = min(len(pdf.pages), self.max_pages)
                self.log.info("PDF has %d pages; rendering %d.", len(pdf.pages), total)
                for i in range(total):
                    page = pdf.pages[i]
                    img = page.to_image(resolution=self.dpi).original  # PIL.Image
                    out_path = os.path.join(out_dir, f"page_{i+1:03d}.png")
                    img.save(out_path, format="PNG")
                    paths.append(out_path)
                    self.log.debug("Rendered page %d -> %s (%s)", i+1, out_path, str(img.size))

        dt = (time.perf_counter() - t0) * 1000
        total_mb = sum(os.path.getsize(p) for p in paths) / (1024 * 1024)
        self.log.info("Rendered %d PNG(s) in %.1f ms (%.1f MB).", len(paths), dt, total_mb)
        return paths

    # ---------- image payload (matches your working code) ----------
    @staticmethod
    def _image_url_part_from_b64(b64: str, mime: str = "image/png") -> dict:
        """
        Returns the exact structure that worked in your direct Azure script:
        {"type":"image_url","image_url":{"url":"data:<mime>;base64,<b64>"}}
        """
        return {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}

    def _paths_to_payloads(self, paths: List[str], mime: str = "image/png") -> List[dict]:
        parts = []
        for p in paths:
            with open(p, "rb") as f:
                b64 = base64.b64encode(f.read()).decode("ascii")
            parts.append(self._image_url_part_from_b64(b64, mime=mime))
            self.log.debug("Prepared %s (%s b64 chars) for image_url payload",
                           os.path.basename(p), len(b64))
        return parts

    # ---------- call with images (image_url shape) ----------
    def _call_with_images(self, prompt: str, paths: List[str]) -> str:
        content = [{"type": "text", "text": prompt}] + self._paths_to_payloads(paths, mime="image/png")
        messages = [
            # order mirrors the working code you shared (user first, then system)
            {"role": "user", "content": content},
            {"role": "system", "content": "You are a precise data-extraction assistant. Output JSON ONLY."},
        ]
        self.log.info("Calling model with IMAGE payload (image_url) — %d page image(s).", len(paths))
        t0 = time.perf_counter()
        resp = self.cli.chat.create(
            model=self.model,
            messages=messages,
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            n=1,
        )
        self.log.info("RAI chat.create (IMAGE) ok in %.1f ms", (time.perf_counter()-t0)*1000)
        msg = resp["choices"][0]["message"]
        out = msg.get("content", "")
        if isinstance(out, list) and out and isinstance(out[0], dict):
            out = out[0].get("text", "")
        return str(out)

    # ---------- TEXT fallback ----------
    @staticmethod
    def _normalize_ws(s: str) -> str:
        s = s.replace("\r", "\n")
        lines = [ln.strip() for ln in s.split("\n")]
        compact, blank = [], False
        for ln in lines:
            if not ln:
                if not blank:
                    compact.append("")
                blank = True
            else:
                compact.append(ln)
                blank = False
        return "\n".join(compact).strip()

    def _text_blocks_from_pdf(self, pdf_path: str) -> List[str]:
        blocks: List[str] = []
        with pdfplumber.open(pdf_path) as pdf:
            total = min(len(pdf.pages), self.max_pages)
            for i in range(total):
                page = pdf.pages[i]
                txt = page.extract_text() or ""
                # keep simple tables (row-wise)
                try:
                    tables = page.extract_tables() or []
                except Exception:
                    tables = []
                for t in tables:
                    for row in (t or []):
                        if not row:
                            continue
                        cells = [(c or "").strip() for c in row]
                        if any(cells):
                            txt += "\n" + " | ".join(cells)
                txt = self._normalize_ws(txt)
                if not txt:
                    continue
                for j in range(0, len(txt), self.page_chunk_chars):
                    chunk = txt[j:j+self.page_chunk_chars]
                    blocks.append(f"PAGE {i+1} CHUNK {j//self.page_chunk_chars+1}:\n{chunk}")
        return blocks

    def _call_text_only(self, prompt: str, text_blocks: List[str]) -> str:
        self.log.info("Calling model with TEXT fallback: %d block(s)", len(text_blocks))
        content = [{"type": "text", "text": prompt}]
        for blk in text_blocks:
            content.append({"type": "text", "text": blk})
        messages = [
            {"role": "system", "content": "You are a precise extraction engine. Reply ONLY with JSON."},
            {"role": "user", "content": content},
        ]
        t0 = time.perf_counter()
        resp = self.cli.chat.create(
            model=self.model, messages=messages,
            max_tokens=self.max_tokens, temperature=self.temperature, n=1
        )
        self.log.info("RAI chat.create (TEXT) ok in %.1f ms", (time.perf_counter()-t0)*1000)
        msg = resp["choices"][0]["message"]
        out = msg.get("content", "")
        if isinstance(out, list) and out and isinstance(out[0], dict):
            out = out[0].get("text", "")
        return str(out)

    # ---------- merge + run ----------
    @staticmethod
    def _merge_items(items: List[KV]) -> List[KV]:
        by_key: dict[str, KV] = {}
        for it in items:
            norm = re.sub(r"[^a-z0-9]+", " ", it.key.lower()).strip()
            if norm not in by_key:
                by_key[norm] = it
            else:
                keep = by_key[norm]
                if len(it.value) > len(keep.value) or it.confidence > keep.confidence:
                    by_key[norm] = it
        return [by_key[k] for k in OrderedDict.fromkeys(by_key.keys())]

    def run(self, pdf_path: str) -> TOrderedDict[str, str]:
        self._validate_model_route()

        # prompt as string
        prompt = (self.prompt | self.to_text).invoke({"allowed_keys_block": self.allowed_block})
        prompt = prompt if isinstance(prompt, str) else str(prompt)

        # Try images first (with exact "image_url" payload shape)
        try:
            pngs = self._pdf_to_png_paths(pdf_path)
            if not pngs:
                raise RuntimeError("No PNGs produced from PDF.")
            raw = self._call_with_images(prompt, pngs)
            payload = self.sanitize.invoke(raw)
            doc = self.parser.parse(payload)
        except Exception as e_img:
            self.log.warning("Image path failed: %s", e_img)
            if not self.text_fallback:
                raise
            # TEXT fallback
            self.log.info("Falling back to TEXT-only extraction...")
            text_blocks = self._text_blocks_from_pdf(pdf_path)
            if not text_blocks:
                raise RuntimeError("TEXT fallback found no extractable text in the PDF.")
            try:
                raw = self._call_text_only(prompt, text_blocks)
                payload = self.sanitize.invoke(raw)
                doc = self.parser.parse(payload)
            except Exception as e_txt:
                self.log.warning("Parse failed on TEXT once (%s). Retrying with strict prompt...", e_txt)
                strict_prompt = (self.prompt_strict | self.to_text).invoke({"allowed_keys_block": self.allowed_block})
                strict_prompt = strict_prompt if isinstance(strict_prompt, str) else str(strict_prompt)
                raw = self._call_text_only(strict_prompt, text_blocks)
                payload = self.sanitize.invoke(raw)
                doc = self.parser.parse(payload)

        items = doc.items or []
        self.log.info("Model returned %d item(s).", len(items))
        merged = self._merge_items(items)
        self.log.info("After merge: %d unique key(s).", len(merged))
        for it in merged:
            self.log.debug("KV: %r = %r (p%d, conf=%.2f)", it.key, it.value, it.page, it.confidence)

        # cleanup temp images
        if getattr(self, "_temp_render_dir", None) and not self.keep_images:
            try:
                shutil.rmtree(self._temp_render_dir, ignore_errors=True)
                self.log.debug("Deleted temp dir %s", self._temp_render_dir)
            except Exception as e:
                self.log.warning("Failed to delete temp render dir: %s", e)

        return OrderedDict((it.key, it.value) for it in merged)


# ======================== CLI ========================

def _default_out(pdf_path: str) -> str:
    base, _ = os.path.splitext(pdf_path)
    return f"{base}.kv.json"

def main():
    ap = argparse.ArgumentParser(description="PDF -> PNG -> LLM KV extractor (RAI, LangChain, with TEXT fallback)")
    ap.add_argument("--cfg", required=True, help="Path to RAI config file ([DEFAULT] format)")
    ap.add_argument("--model", required=True, help="LLM route (must exist on your gateway)")
    ap.add_argument("--pdf", required=True, help="Input PDF path")
    ap.add_argument("--out", default=None, help="Output JSON path (default: <pdf>.kv.json)")
    ap.add_argument("--allowed_keys", default=None, help="Comma-separated whitelist of keys (optional)")
    ap.add_argument("--max-pages", type=int, default=10, help="Max pages to consider")
    ap.add_argument("--dpi", type=int, default=200, help="PNG render DPI")
    ap.add_argument("--max-tokens", type=int, default=1300, help="Max tokens for model output")
    ap.add_argument("--temperature", type=float, default=0.0, help="Sampling temperature")
    ap.add_argument("--dump-images", default=None, help="Folder to save rendered PNGs (kept)")
    ap.add_argument("--keep-images", action="store_true", help="Keep temp images even if dump not set")
    ap.add_argument("--log-level", default="INFO", choices=["DEBUG","INFO","WARNING","ERROR"], help="Logging verbosity")
    ap.add_argument("--log-file", default=None, help="Optional log file path")
    ap.add_argument("--text-fallback", action="store_true", default=True,
                    help="Enable TEXT-only fallback if image calls fail (default on)")
    ap.add_argument("--page-chars", type=int, default=12000,
                    help="Max chars per page chunk for TEXT fallback")
    ap.add_argument("--force-format", choices=["dataurl","base64","generic"], default=None,
                    help="(kept for compatibility; currently all image modes use image_url payload)")
    ap.add_argument("--profile", default=None,
                    help="Optional RAI profile (e.g., NO_GUARDRAIL)")

    args = ap.parse_args()
    logger = setup_logger(args.log_level, args.log_file)
    allowed = [k.strip() for k in args.allowed_keys.split(",")] if args.allowed_keys else None

    agent = PDF2JSON(
        cfg=args.cfg,
        model=args.model,
        temperature=args.temperature,
        max_tokens=args.max_tokens,
        allowed_keys=allowed,
        max_pages=args.max_pages,
        dpi=args.dpi,
        dump_images=args.dump_images,
        keep_images=args.keep_images,
        logger=logger,
        text_fallback=args.text_fallback,
        page_chunk_chars=args.page_chars,
        force_format=args.force_format,
        profile=args.profile,
    )

    kv = agent.run(args.pdf)
    out_path = args.out or _default_out(args.pdf)
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(kv, f, indent=2, ensure_ascii=False)
    logger.info("Wrote key–value JSON to: %s", out_path)


if __name__ == "__main__":
    main()
