# app_streamlit.py
# Streamlit 1.45.1 UI for: PDF -> PNG -> LLM -> KV JSON (+ schema gen + optional projection)

import json
import tempfile
import streamlit as st
from pathlib import Path

# ---- import your CLI engine as a module (recommended) ----
# from pdf_to_json_agent_langgraph import (
#     build_app, generate_json_schema, project_to_schema,
#     SSRAIClient, setup_logger
# )
# If you prefer a single-file app, you can paste the small wrapper
# functions here or import just what you need.

from pdf_to_json_agent_langgraph import (
    build_app, generate_json_schema, project_to_schema
)

st.set_page_config(page_title="PDF → JSON (KV + Schema)", layout="wide")

st.title("PDF → JSON (KV + Schema) — LangGraph + RAI")

with st.expander("Configuration", expanded=True):
    colA, colB = st.columns(2)
    with colA:
        cfg_path = st.text_input("RAI config file path", value="", help="Path to your rai_config.cfg")
        model_route = st.text_input("Model route", value="azure-openai.gpt-4o")
        profile = st.text_input("RAI Profile (optional)", value="")
        user_prompt = st.text_area(
            "User prompt (optional)",
            value="Extract invoice number, date, seller, buyer, line items, totals.",
            height=100
        )
        allowed_keys_raw = st.text_input("Allowed keys (comma-separated, optional)", value="")
        max_pages = st.number_input("Max pages", min_value=1, max_value=500, value=10, step=1)
        dpi = st.number_input("Render DPI", min_value=100, max_value=600, value=200, step=25)
    with colB:
        max_tokens = st.number_input("Max tokens", min_value=256, max_value=4096, value=1300, step=64)
        temperature = st.number_input("Temperature", min_value=0.0, max_value=2.0, value=0.0, step=0.1)
        text_fallback = st.checkbox("Enable TEXT fallback", value=True)
        page_chars = st.number_input("TEXT page chunk size (chars)", min_value=2000, max_value=40000, value=12000, step=1000)
        keep_images = st.checkbox("Keep rendered images on disk", value=False)
        dump_dir = st.text_input("Dump images to folder (optional)", value="")

with st.expander("Optional Input JSON Schema (Draft-07)", expanded=False):
    schema_text = st.text_area(
        "Paste schema JSON here (optional)",
        value="",
        height=160,
        help="If provided, we will also project the extracted KV map into this schema."
    )

pdf_file = st.file_uploader("Upload PDF", type=["pdf"])

run = st.button("Run Extraction", type="primary", disabled=(pdf_file is None or not cfg_path or not model_route))

if run:
    if not pdf_file:
        st.error("Please upload a PDF.")
        st.stop()
    if not cfg_path or not model_route:
        st.error("Please provide RAI config path and model route.")
        st.stop()

    # Write upload to a temp file
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tf:
        tf.write(pdf_file.read())
        pdf_path = tf.name

    # Parse optional inputs
    allowed = [k.strip() for k in allowed_keys_raw.split(",")] if allowed_keys_raw.strip() else None
    schema_in = None
    if schema_text.strip():
        try:
            schema_in = json.loads(schema_text)
        except Exception as e:
            st.warning(f"Schema JSON could not be parsed: {e}")
            schema_in = None

    # Prepare init state for the LangGraph app
    init_state = {
        "cfg": cfg_path,
        "model": model_route,
        "pdf": pdf_path,
        "out": str(Path(pdf_path).with_suffix(".kv.json")),
        "allowed_keys": allowed,
        "user_prompt": user_prompt or None,
        "schema_in": schema_in,
        "out_schema": str(Path(pdf_path).with_suffix(".schema.json")),
        "out_structured": str(Path(pdf_path).with_suffix(".structured.json")),
        "max_pages": int(max_pages),
        "dpi": int(dpi),
        "max_tokens": int(max_tokens),
        "temperature": float(temperature),
        "dump_images": dump_dir or None,
        "keep_images": bool(keep_images),
        "text_fallback": bool(text_fallback),
        "page_chunk_chars": int(page_chars),
        "profile": profile or None,
        "log_level": "INFO",
        "log_file": None,
    }

    st.info("Running… this may take a moment depending on pages and model latency.")
    app = build_app().compile()
    final_state = app.invoke(init_state)

    kv_map = final_state.get("kv_map", {})
    if not kv_map:
        st.error("No KV output produced.")
        st.stop()

    # 1) show KV map
    st.subheader("Key–Value JSON")
    st.json(kv_map)
    st.download_button(
        "Download KV JSON",
        data=json.dumps(kv_map, indent=2, ensure_ascii=False),
        file_name="extracted.kv.json",
        mime="application/json"
    )

    # 2) inferred schema
    inferred = generate_json_schema(kv_map)
    st.subheader("Inferred JSON Schema (Draft-07)")
    st.code(json.dumps(inferred, indent=2, ensure_ascii=False), language="json")
    st.download_button(
        "Download Inferred Schema",
        data=json.dumps(inferred, indent=2, ensure_ascii=False),
        file_name="extracted.schema.json",
        mime="application/json"
    )

    # 3) project to provided schema (if any)
    if schema_in:
        structured = project_to_schema(kv_map, schema_in)
        st.subheader("Structured JSON (Projected into Input Schema)")
        st.json(structured)
        st.download_button(
            "Download Structured JSON",
            data=json.dumps(structured, indent=2, ensure_ascii=False),
            file_name="extracted.structured.json",
            mime="application/json"
        )

    st.success("Done ✓")
