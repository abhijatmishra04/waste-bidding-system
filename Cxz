
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Locust Metrics Worker
---------------------
Continuously reads logs/latency_feed.jsonl (generated by RAIGatewayClient)
and computes precise metrics using Locustâ€™s official RequestStats engine.

Uses:
 - env.stats.log_request() and env.stats.log_error() (official Locust API)
 - Writes metrics snapshots every few seconds to logs/locust_metrics.jsonl
 - Does not use gevent monkey patching
"""

import os
import time
import json
import logging
from logging.handlers import RotatingFileHandler
from locust.env import Environment  # Official Locust engine

# File paths
FEED = "logs/latency_feed.jsonl"
OUT = "logs/locust_metrics.jsonl"
OFFSET_FILE = "logs/locust_feed.offset"
SNAP_INTERVAL = 5  # seconds


# ---------------- Logging Setup ----------------
def _rot_logger(path: str) -> logging.Logger:
    logger = logging.getLogger("locust.metrics")
    logger.setLevel(logging.INFO)
    logger.propagate = False
    if not logger.handlers:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        fh = RotatingFileHandler(path, maxBytes=10 * 1024 * 1024, backupCount=3)
        fh.setFormatter(logging.Formatter("%(message)s"))
        logger.addHandler(fh)
    return logger


# ---------------- Offset Handling ----------------
def _read_offset() -> int:
    """Read last processed byte offset from file."""
    try:
        return int(open(OFFSET_FILE).read().strip() or "0")
    except Exception:
        return 0


def _write_offset(o: int):
    """Write current file offset to checkpoint file."""
    os.makedirs(os.path.dirname(OFFSET_FILE), exist_ok=True)
    with open(OFFSET_FILE, "w") as f:
        f.write(str(o))


# ---------------- Metrics Snapshot ----------------
def _snapshot(env: Environment) -> dict:
    """Collect overall and per-model Locust statistics."""
    s = env.stats.total
    snap = {
        "ts": time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime()),
        "locust_num_requests": s.num_requests,
        "locust_num_failures": s.num_failures,
        "locust_success_rate_pct": round(((s.num_requests - s.num_failures) / s.num_requests * 100) if s.num_requests else 0, 2),
        "locust_avg_latency_ms": round(getattr(s, "avg_response_time", 0.0), 2),
        "locust_p50_latency_ms": round(s.get_response_time_percentile(0.50) or 0.0, 2),
        "locust_p95_latency_ms": round(s.get_response_time_percentile(0.95) or 0.0, 2),
        "current_rps": round(getattr(s, "current_rps", 0.0), 2),
    }

    # Include per-model metrics
    for (req_type, name), entry in env.stats.entries.items():
        if req_type != "RAI":
            continue
        snap[f"model::{name}"] = {
            "num_requests": entry.num_requests,
            "num_failures": entry.num_failures,
            "avg_ms": round(entry.avg_response_time, 2),
            "p50_ms": round(entry.get_response_time_percentile(0.50) or 0.0, 2),
            "p95_ms": round(entry.get_response_time_percentile(0.95) or 0.0, 2),
        }

    return snap


# ---------------- Main Worker Loop ----------------
def main():
    """Continuously read latency feed and update Locust statistics."""
    log = _rot_logger(OUT)
    env = Environment(user_classes=[])
    offset = _read_offset()

    os.makedirs(os.path.dirname(FEED), exist_ok=True)
    with open(FEED, "a+", encoding="utf-8") as f:
        f.seek(offset)
        last_snapshot = time.time()

        print("[LocustWorker] Started. Monitoring:", FEED)
        try:
            while True:
                line = f.readline()
                if not line:
                    time.sleep(0.25)
                    continue

                offset = f.tell()
                try:
                    record = json.loads(line)
                    model = str(record.get("model") or "UNKNOWN")
                    ok = bool(record.get("ok"))
                    latency = int(record.get("latency_ms") or 0)

                    # Record success or failure using official Locust APIs
                    if ok:
                        env.stats.log_request(
                            request_type="RAI",
                            name=model,
                            response_time=latency,
                            response_length=0,
                        )
                    else:
                        env.stats.log_error(
                            request_type="RAI",
                            name=model,
                            exception=RuntimeError(record.get("error") or "error"),
                        )

                except Exception as ex:
                    print("[LocustWorker] Feed parse error:", ex, "line:", line.strip())

                # Periodic metrics snapshot
                if time.time() - last_snapshot >= SNAP_INTERVAL:
                    last_snapshot = time.time()
                    snap = _snapshot(env)
                    log.info(json.dumps(snap))
                    _write_offset(offset)
                    print(f"[Metrics] Total={snap['locust_num_requests']} "
                          f"Avg={snap['locust_avg_latency_ms']}ms "
                          f"P50={snap['locust_p50_latency_ms']} "
                          f"P95={snap['locust_p95_latency_ms']} "
                          f"Failures={snap['locust_num_failures']}")

        except KeyboardInterrupt:
            print("\n[LocustWorker] Stopped.")
            _write_offset(offset)


if __name__ == "__main__":
    main()
