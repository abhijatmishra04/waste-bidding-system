#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAI Gateway client with:
- Retries + circuit breaker
- Manual sliding-window metrics (avg/p50/p95)
- Locust inbuilt metrics (avg/p50/p95) WITHOUT gevent ssl monkey-patch
- Separate rotating logs for events, manual metrics, and locust metrics
"""

import os
import time
import math
import json
import random
import logging
import threading
from logging.handlers import RotatingFileHandler
from collections import deque
from typing import Any, Callable, Deque, Dict, List, Optional

# --------------------------------------------------------------------
# Safety: disable Locust/gevent monkey-patching (prevents SSL loops)
# Must be set before any Locust import in this process.
# --------------------------------------------------------------------
os.environ.setdefault("LOCUST_NO_MONKEY_PATCH", "1")

# Official RAI Gateway SDK
from ssrai import SSRAIClient


# ----------------- BASE LOGGER (general events) -----------------
logger = logging.getLogger("RAIGatewayClient")
logger.setLevel(logging.INFO)
logger.propagate = False
if not logger.handlers:
    _h = logging.StreamHandler()
    _h.setFormatter(logging.Formatter("%(message)s"))
    logger.addHandler(_h)


# ----------------- CIRCUIT BREAKER -----------------
class CircuitBreaker:
    """Stops calls temporarily when repeated failures occur."""

    def __init__(self, fail_threshold: int = 10, half_open_after: float = 30.0):
        self.state = "CLOSED"  # CLOSED | OPEN | HALF_OPEN
        self.fail_count = 0
        self.opened_at = 0.0
        self.fail_threshold = fail_threshold
        self.half_open_after = half_open_after
        self._lock = threading.Lock()

    def allow(self) -> bool:
        with self._lock:
            if self.state == "OPEN" and (time.time() - self.opened_at) > self.half_open_after:
                self.state = "HALF_OPEN"  # allow one probe call
            return self.state != "OPEN"

    def on_success(self):
        with self._lock:
            self.fail_count = 0
            self.state = "CLOSED"

    def on_failure(self):
        with self._lock:
            self.fail_count += 1
            if self.fail_count >= self.fail_threshold and self.state != "OPEN":
                self.state = "OPEN"
                self.opened_at = time.time()

    def get_state(self) -> str:
        with self._lock:
            return self.state


# ----------------- CUSTOM ERROR -----------------
class RAIError(Exception):
    def __init__(self, code: str, message: str):
        super().__init__(message)
        self.code = code


# ----------------- MAIN CLIENT -----------------
class RAIGatewayClient:
    """
    Robust wrapper for SSRAIClient with:
      - Retries (exponential backoff + jitter)
      - Circuit breaker protection
      - Manual sliding-window latency metrics (avg/p50/p95)
      - Locust-backed metrics (avg/p50/p95 + totals), without monkey-patching
      - Structured JSON logging (PII-safe) to console + rotating files
      - Auto PAT/OAuth handling (from config or env)
    """

    def __init__(
        self,
        config_file: str,
        profile: Optional[str] = None,
        *,
        max_retries: int = 3,
        backoff_base_seconds: float = 0.5,
        backoff_max_seconds: float = 10.0,
        max_total_retry_seconds: float = 30.0,
        metrics_window_size: int = 5000,
        breaker_fail_threshold: int = 10,
        breaker_half_open_after: float = 30.0,
        on_failure: Optional[Callable[[Dict[str, Any]], None]] = None,
        extra_log_fields: Optional[Dict[str, Any]] = None,
        # general events log
        log_file: Optional[str] = "rai_client_events.jsonl",
        log_max_bytes: int = 10 * 1024 * 1024,
        log_backup_count: int = 3,
        # Locust
        enable_locust_metrics: bool = True,
        # separate metrics logs
        manual_metrics_log_file: Optional[str] = "manual_metrics.jsonl",
        locust_metrics_log_file: Optional[str] = "locust_metrics.jsonl",
        metrics_log_every_call: bool = True,
    ):
        # 1) Create SSRAI client first (before importing Locust)
        self.cli = SSRAIClient(config_file=config_file, profile=profile)

        # âœ… ensure exists BEFORE any _log() usage
        self.extra_log_fields = extra_log_fields or {}

        # 2) Inject PAT if needed
        if getattr(self.cli, "auth_type", None) == "pat" and not getattr(self.cli, "pat_token", None):
            env_pat = os.getenv("SSRAI_PAT_TOKEN")
            if env_pat:
                self.cli.pat_token = env_pat
                self._log("info", "pat_injected", "PAT token loaded from env")

        # 3) Set up general rotating file handler (optional)
        if log_file:
            self._add_rotating_handler(logger, log_file, log_max_bytes, log_backup_count)
            self._log("info", "file_logging_enabled", f"events_log={os.path.abspath(log_file)}")

        # Retry/backoff config
        self.max_retries = int(max_retries)
        self.backoff_base_seconds = float(backoff_base_seconds)
        self.backoff_max_seconds = float(backoff_max_seconds)
        self.max_total_retry_seconds = float(max_total_retry_seconds)

        # Manual sliding-window metrics state
        self._latencies_ms: Deque[float] = deque(maxlen=int(metrics_window_size))
        self._total_calls = 0
        self._failures = 0
        self._lock = threading.Lock()

        # Circuit breaker
        self._breaker = CircuitBreaker(breaker_fail_threshold, breaker_half_open_after)

        # Hooks
        self.on_failure = on_failure

        # Dedicated metrics loggers (separate files)
        self._manual_metrics_logger = logging.getLogger("RAIGatewayClient.manual")
        self._manual_metrics_logger.setLevel(logging.INFO)
        self._manual_metrics_logger.propagate = False
        if not self._manual_metrics_logger.handlers:
            _mh = logging.StreamHandler()
            _mh.setFormatter(logging.Formatter("%(message)s"))
            self._manual_metrics_logger.addHandler(_mh)
        if manual_metrics_log_file:
            self._add_rotating_handler(
                self._manual_metrics_logger, manual_metrics_log_file, log_max_bytes, log_backup_count
            )

        self._locust_metrics_logger = logging.getLogger("RAIGatewayClient.locust")
        self._locust_metrics_logger.setLevel(logging.INFO)
        self._locust_metrics_logger.propagate = False
        if not self._locust_metrics_logger.handlers:
            _lh = logging.StreamHandler()
            _lh.setFormatter(logging.Formatter("%(message)s"))
            self._locust_metrics_logger.addHandler(_lh)
        if locust_metrics_log_file:
            self._add_rotating_handler(
                self._locust_metrics_logger, locust_metrics_log_file, log_max_bytes, log_backup_count
            )

        self._metrics_log_every_call = bool(metrics_log_every_call)

        # 4) Lazily import and init Locust AFTER SSRAIClient (no gevent monkey-patch)
        self._locust_env = None
        if enable_locust_metrics:
            try:
                from locust.env import Environment  # type: ignore
            except Exception as e:
                raise ImportError(
                    "Locust metrics requested but Locust is not available. "
                    'Install with: pip install "locust==2.41.2"'
                ) from e
            self._locust_env = Environment(user_classes=[])
            _ = self._locust_env.stats  # ensure stats is created
            self._log("info", "locust_enabled", "Locust metrics enabled (no monkey patch)")

    # ----------------- Utilities -----------------
    @staticmethod
    def _add_rotating_handler(log_obj: logging.Logger, path: str, max_bytes: int, backups: int):
        # auto-create directories if needed
        abs_path = os.path.abspath(path)
        try:
            os.makedirs(os.path.dirname(abs_path), exist_ok=True)
        except Exception:
            pass
        # de-dupe for same path
        for h in log_obj.handlers:
            if isinstance(h, RotatingFileHandler) and getattr(h, "baseFilename", None) == abs_path:
                return
        fh = RotatingFileHandler(abs_path, maxBytes=max_bytes, backupCount=backups)
        fh.setFormatter(logging.Formatter("%(message)s"))
        fh.setLevel(logging.INFO)
        log_obj.addHandler(fh)

    def _log(self, level: str, event: str, msg: str, extra: Optional[Dict[str, Any]] = None):
        payload = {
            "ts": time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime()),
            "event": event,
            "message": msg,
        }
        # extra fields (e.g., env, app, host) supplied by caller
        payload.update(self.extra_log_fields)
        if extra:
            payload.update(extra)
        line = json.dumps(payload, ensure_ascii=False)
        getattr(logger, level if hasattr(logger, level) else "info")(line)

    def _compute_backoff(self, attempt: int) -> float:
        base = self.backoff_base_seconds * (2 ** attempt)
        return random.uniform(0, min(base, self.backoff_max_seconds))

    # ----------------- Manual metrics -----------------
    @staticmethod
    def _percentile(sorted_values: List[float], p: float) -> float:
        if not sorted_values:
            return 0.0
        k = (len(sorted_values) - 1) * (p / 100.0)
        f = math.floor(k)
        c = math.ceil(k)
        if f == c:
            return sorted_values[int(k)]
        return sorted_values[f] * (c - k) + sorted_values[c] * (k - f)

    def get_manual_metrics(self) -> Dict[str, Any]:
        with self._lock:
            lat = list(self._latencies_ms)
            total = self._total_calls
            fails = self._failures

        lat_sorted = sorted(lat)
        p50 = self._percentile(lat_sorted, 50.0) if lat_sorted else 0.0
        p95 = self._percentile(lat_sorted, 95.0) if lat_sorted else 0.0
        avg = (sum(lat_sorted) / len(lat_sorted)) if lat_sorted else 0.0
        success = total - fails
        success_rate = (success / total * 100.0) if total else 0.0

        return {
            "manual_total_calls": total,
            "manual_failures": fails,
            "manual_success_rate_pct": round(success_rate, 2),
            "manual_avg_latency_ms": round(avg, 2),
            "manual_p50_latency_ms": round(p50, 2),
            "manual_p95_latency_ms": round(p95, 2),
        }

    # ----------------- Locust metrics -----------------
    def _record_locust(self, *, name: str, latency_ms: float, ok: bool, err: Optional[Exception]):
        if not self._locust_env:
            return
        try:
            self._locust_env.events.request.fire(
                request_type="RAI",
                name=name,
                response_time=latency_ms,
                response_length=0,
                exception=(None if ok else err),
                context={},
            )
        except Exception as e:
            self._log("warning", "locust_record_error", str(e))

    def get_locust_metrics(self, name: Optional[str] = None) -> Dict[str, Any]:
        if not self._locust_env:
            return {}
        stats = self._locust_env.stats
        s = stats.get("RAI", name) if name else stats.total
        try:
            p50 = s.get_current_response_time_percentile(0.50) or 0.0
            p95 = s.get_current_response_time_percentile(0.95) or 0.0
        except Exception:
            p50 = 0.0
            p95 = 0.0

        total = getattr(s, "num_requests", 0)
        fails = getattr(s, "num_failures", 0)
        succ = total - fails
        success_rate = (succ / total * 100.0) if total else 0.0

        return {
            "locust_scope": (name or "TOTAL"),
            "locust_num_requests": total,
            "locust_num_failures": fails,
            "locust_success_rate_pct": round(success_rate, 2),
            "locust_avg_latency_ms": round(getattr(s, "avg_response_time", 0.0), 2),
            "locust_p50_latency_ms": round(p50, 2),
            "locust_p95_latency_ms": round(p95, 2),
            "locust_current_rps": round(getattr(self._locust_env.stats.total, "current_rps", 0.0), 2),
        }

    def reset_metrics(self):
        if self._locust_env:
            self._locust_env.stats.reset_all()
        with self._lock:
            self._latencies_ms.clear()
            self._total_calls = 0
            self._failures = 0

    # ----------------- Combined metrics + per-call snapshots -----------------
    def _log_metrics_snapshot(self, name: Optional[str]):
        now = time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime())

        manual = self.get_manual_metrics()
        mline = {"ts": now, **self.extra_log_fields, **manual}
        self._manual_metrics_logger.info(json.dumps(mline, ensure_ascii=False))

        if self._locust_env:
            locust = self.get_locust_metrics(name=name)
            lline = {"ts": now, **self.extra_log_fields, **locust}
            self._locust_metrics_logger.info(json.dumps(lline, ensure_ascii=False))

    def get_metrics(self, name: Optional[str] = None) -> Dict[str, Any]:
        out = {
            "breaker_state": self._breaker.get_state(),
            "manual": self.get_manual_metrics(),
        }
        if self._locust_env:
            out["locust"] = self.get_locust_metrics(name=name)
        return out

    # ----------------- Core call -----------------
    def call_chat(
        self,
        messages: List[Dict[str, Any]],
        model: str,
        *,
        max_tokens: int = 512,
        temperature: float = 0.0,
        guardrail_profile: Optional[str] = None,
    ) -> Dict[str, Any]:

        if not self._breaker.allow():
            with self._lock:
                self._failures += 1
            self._record_locust(name=model, latency_ms=0.0, ok=False, err=RAIError("Circuit.Open", "OPEN"))
            raise RAIError("Circuit.Open", "Circuit breaker is OPEN")

        start_overall = time.perf_counter()
        last_exc: Optional[Exception] = None

        for attempt in range(self.max_retries + 1):
            self._log("info", "retry_attempt_start", f"attempt={attempt+1}/{self.max_retries+1}", {"model": model})
            t0 = time.perf_counter()
            try:
                resp = self.cli.chat.create(
                    model=model,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    guardrail_profile=guardrail_profile,
                )
                latency_ms = (time.perf_counter() - t0) * 1000.0

                with self._lock:
                    self._total_calls += 1
                    self._latencies_ms.append(latency_ms)

                self._breaker.on_success()
                self._record_locust(name=model, latency_ms=latency_ms, ok=True, err=None)

                self._log(
                    "info",
                    "retry_attempt_end",
                    "success",
                    {"attempt": attempt + 1, "latency_ms": round(latency_ms, 2), "model": model},
                )

                if self._metrics_log_every_call:
                    self._log_metrics_snapshot(name=model)
                return resp

            except Exception as e:
                last_exc = e
                elapsed = time.perf_counter() - start_overall
                final = (attempt >= self.max_retries) or (elapsed >= self.max_total_retry_seconds)

                with self._lock:
                    self._failures += 1
                self._breaker.on_failure()

                latency_ms = (time.perf_counter() - t0) * 1000.0
                self._record_locust(name=model, latency_ms=latency_ms, ok=False, err=e)

                self._log(
                    "warning",
                    "retry_attempt_end",
                    "failure",
                    {
                        "attempt": attempt + 1,
                        "error": str(e),
                        "retry_planned": (not final),
                        "breaker": self._breaker.get_state(),
                        "latency_ms": round(latency_ms, 2),
                        "model": model,
                    },
                )

                if self.on_failure:
                    try:
                        self.on_failure({"attempt": attempt + 1, "error": str(e), "model": model})
                    except Exception as cb:
                        self._log("error", "failure_callback_error", str(cb))

                if final:
                    if self._metrics_log_every_call:
                        self._log_metrics_snapshot(name=model)
                    break

                time.sleep(self._compute_backoff(attempt))

        self._log("error", "rai_ultimate_failure", f"failed after {self.max_retries + 1} attempts", {"model": model})
        raise RAIError("Call.Failed", "RAI call failed") from last_exc

    # ----------------- Factory -----------------
    @classmethod
    def from_cfg(cls, cfg_path: str, *, profile: Optional[str] = None, **kwargs):
        return cls(config_file=cfg_path, profile=profile, **kwargs)
