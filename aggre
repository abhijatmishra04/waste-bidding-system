@Data
public class RetrievalDTO {

    private String transactionReferenceId; // RETR-STB-TRAN-REF-ID  -> TRAN REF ID
    private String accountNumber;          // RETR-STB-ACCOUNT-NUMBER -> CC-ACCOUNT NUMBER
    private String paymentType;            // RETR-STB-PAYMENT-TYPE -> PAYMENT TYPE
    private String dueDate;                // RETR-STB-DUE-DATE -> DUE DATE
    private Long HangingDays;              // RETR-STB-HANGING-DAYS -> HANGING DAYS
    private String marketId;               // RETR-STB-MARKET-ID -> MARKET ID
    private String createTimestamp;        // RETR-STB-CREATE-TIMESTAMP -> CREATE TIMESTAMP

    // This method returns only the fields present in the screenshot to be mapped to the output file.
    public static String[] outputFields() {
        return new String[] {
            "transactionReferenceId", // Maps to TRAN REF ID in the flat file
            "accountNumber",          // Maps to CC-ACCOUNT NUMBER in the flat file
            "paymentType",            // Maps to PAYMENT TYPE in the flat file
            "dueDate",                // Maps to DUE DATE in the flat file
            "HangingDays",            // Maps to HANGING DAYS in the flat file
            "marketId",               // Maps to MARKET ID in the flat file
            "createTimestamp"         // Maps to CREATE TIMESTAMP in the flat file
        };
    }
}

formatterAggregator.setFormat("%-10s%-20s%-5s%-10s%-10s%-4s%-26s");


@Bean(name = "dayPlusOneWriter")
@StepScope
public FlatFileItemWriter<RetrievalDTO> dayPlusOneWriter() {
    Log.info("dayPlusOneWriter ::: flatFileItemWriter() :: Thread Id: {}, Thread name: {}",
            Thread.currentThread().getId(), Thread.currentThread().getName());

    String threadParam = Thread.currentThread().getId() + "-" + Thread.currentThread().getName() + "-" + new Random().nextInt();

    this.outputFlatFilePath = dynamicConfigPropRepository
            .findPropertyValueByPropertyName("collectionletters.output.flat.file.path");
    this.aggregatorFormat = dynamicConfigPropRepository
            .findPropertyValueByPropertyName("collectionletters.aggregator.format");
    this.flatfileWriterName = dynamicConfigPropRepository
            .findPropertyValueByPropertyName("collectionletters.flatfile.writer.name");

    FlatFileItemWriter<RetrievalDTO> itemWriter = new FlatFileItemWriter<>();

    // Counter to keep track of records
    AtomicInteger recordCount = new AtomicInteger();

    itemWriter.setHeaderCallback(new FlatFileHeaderCallback() {
        @Override
        public void writeHeader(Writer header) throws IOException {
            header.write(SdpRespConstants.HANGING_HEADER1);
            Log.info("dayPlusOneWriter ::: flatFileItemWriter() ::: Headers are set :::" + header);
        }
    });

    itemWriter.setFooterCallback(new FlatFileFooterCallback() {
        @Override
        public void writeFooter(Writer footer) throws IOException {
            // Write the record count in the trailer/footer
            footer.write(SdpRespConstants.SST_REC_ID_TLR + SdpRespConstants.SPACES_172);
            footer.write(String.format("Total Record Count: %d", recordCount.get()));
            Log.info("dayPlusOneWriter ::: flatFileItemWriter() ::: Footers are set :::" + footer);
        }
    });

    itemWriter.setName(flatfileWriterName);
    itemWriter.setResource(new FileSystemResource(outputFlatFilePath + "/" + threadParam + "dayPlusOneWriter.txt"));

    FormatterLineAggregator<RetrievalDTO> formatterAggregator = new FormatterLineAggregator<>();
    BeanWrapperFieldExtractor<RetrievalDTO> extractor = new BeanWrapperFieldExtractor<>();
    extractor.setNames(RetrievalDTO.outputFields());
    formatterAggregator.setFieldExtractor(extractor);
    formatterAggregator.setFormat(aggregatorFormat);
    itemWriter.setLineAggregator(formatterAggregator);

    // Increment record count on each record write
    itemWriter.setAfterWriteListener(new ItemWriteListener<RetrievalDTO>() {
        @Override
        public void afterWrite(List<? extends RetrievalDTO> items) {
            recordCount.addAndGet(items.size());
        }
    });

    Log.info("dayPlusOneWriter ::: flatFileItemWriter() ::: writer Object ::: {}", itemWriter);

    return itemWriter;
}





import lombok.extern.log4j.Log4j2;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.stereotype.Component;

import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.time.temporal.ChronoUnit;
import java.time.DayOfWeek;
import java.util.concurrent.atomic.AtomicInteger;

@Component
@Log4j2
public class RetrievalDTOProcessor implements ItemProcessor<RetrievalDTO, RetrievalDTO> {

    private static final AtomicInteger recordCounter = new AtomicInteger(0); // Record counter
    private static final String DATE_FORMAT = "yyyyMMdd"; // Assuming dueDate is in this format

    @Override
    public RetrievalDTO process(RetrievalDTO item) throws Exception {
        // Log when a record starts being processed
        log.info("Starting to process record: {}", item.getDetailRecordId());

        // Step 1: Filter records
        if (!"COL".equals(item.getSubChannel()) || Double.parseDouble(item.getStatementBalance()) <= 0.0) {
            log.info("Record with ID {} is being filtered out due to subChannel or statement balance.", item.getDetailRecordId());
            return null; // Skip invalid records
        }

        // Step 2: Calculate the hanging days
        LocalDate dueDate = LocalDate.parse(item.getDueDate(), DateTimeFormatter.ofPattern(DATE_FORMAT));
        LocalDate currentDate = LocalDate.now();
        DayOfWeek dayOfWeek = currentDate.getDayOfWeek();
        long hangingDays;

        if (dayOfWeek == DayOfWeek.SUNDAY) {
            // If today is Sunday, calculate hanging days based on a 6-day difference
            hangingDays = ChronoUnit.DAYS.between(dueDate.minusDays(6), currentDate);
            log.info("Hanging days for record {} calculated as {} (Sunday adjustment).", item.getDetailRecordId(), hangingDays);
        } else {
            // Otherwise, use a 5-day difference
            hangingDays = ChronoUnit.DAYS.between(dueDate.minusDays(5), currentDate);
            log.info("Hanging days for record {} calculated as {} (Weekday adjustment).", item.getDetailRecordId(), hangingDays);
        }

        // Increment the record count for each valid record
        int currentCount = recordCounter.incrementAndGet();
        log.info("Record count after processing record {}: {}", item.getDetailRecordId(), currentCount);

        // Step 3: Map fields to a new DTO
        RetrievalDTO reportDTO = new RetrievalDTO();
        reportDTO.setDetailRecordId(item.getDetailRecordId());
        reportDTO.setHangingDays(hangingDays);
        reportDTO.setPaymentType(item.getPaymentType());
        reportDTO.setAccountNumber(item.getAccountNumber());
        reportDTO.setConfirmationNumber(item.getConfirmationNumber());
        reportDTO.setDueDate(item.getDueDate());
        reportDTO.setMarketId(item.getMarketId());
        reportDTO.setCreateTimestamp(item.getCreateTimestamp());

        // Log that the record has been processed successfully
        log.info("Record {} processed successfully.", item.getDetailRecordId());

        return reportDTO;
    }

    // Method to get the total processed record count
    public static int getTotalRecordCount() {
        return recordCounter.get();
    }
}



import lombok.extern.log4j.Log4j2;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.stereotype.Component;

import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.time.temporal.ChronoUnit;
import java.time.DayOfWeek;
import java.util.concurrent.atomic.AtomicInteger;

@Component
@Log4j2
public class RetrievalDTOProcessor implements ItemProcessor<RetrievalDTO, RetrievalDTO> {

    private static final AtomicInteger recordCounter = new AtomicInteger(0); // Record counter
    private static final String DATE_FORMAT = "yyyyMMdd"; // Assuming dueDate is in this format

    @Override
    public RetrievalDTO process(RetrievalDTO item) throws Exception {
        // Step 1: Filter records
        if (!"COL".equals(item.getSubChannel()) || Double.parseDouble(item.getStatementBalance()) <= 0.0) {
            log.info("Record with DetailRecordId {} is being filtered out due to subChannel or statement balance.", item.getDetailRecordId());
            return null; // Skip invalid records
        }

        // Increment the record count for each valid record
        int currentCount = recordCounter.incrementAndGet();
        log.info("Processing valid record #{}", currentCount);

        // Step 2: Calculate the hanging days
        LocalDate dueDate = LocalDate.parse(item.getDueDate(), DateTimeFormatter.ofPattern(DATE_FORMAT));
        LocalDate currentDate = LocalDate.now();
        DayOfWeek dayOfWeek = currentDate.getDayOfWeek();
        long hangingDays;

        if (dayOfWeek == DayOfWeek.SUNDAY) {
            // If today is Sunday, calculate hanging days based on a 6-day difference
            hangingDays = ChronoUnit.DAYS.between(dueDate.minusDays(6), currentDate);
            log.info("Hanging days for valid record #{} calculated as {} (Sunday adjustment).", currentCount, hangingDays);
        } else {
            // Otherwise, use a 5-day difference
            hangingDays = ChronoUnit.DAYS.between(dueDate.minusDays(5), currentDate);
            log.info("Hanging days for valid record #{} calculated as {} (Weekday adjustment).", currentCount, hangingDays);
        }

        // Step 3: Map fields to a new DTO
        RetrievalDTO reportDTO = new RetrievalDTO();
        reportDTO.setDetailRecordId("D");  // DetailRecordId is constant "D"
        reportDTO.setHangingDays(hangingDays);
        reportDTO.setPaymentType(item.getPaymentType());
        reportDTO.setAccountNumber(item.getAccountNumber());
        reportDTO.setConfirmationNumber(item.getConfirmationNumber());
        reportDTO.setDueDate(item.getDueDate());
        reportDTO.setMarketId(item.getMarketId());
        reportDTO.setCreateTimestamp(item.getCreateTimestamp());

        // Log that the record has been processed successfully
        log.info("Valid record #{} processed successfully.", currentCount);

        return reportDTO;
    }

    // Method to get the total processed valid record count
    public static int getTotalRecordCount() {
        return recordCounter.get();
    }
}


@Bean(name = "dayPlusOneWriter")
@StepScope
public FlatFileItemWriter<RetrievalDTO> dayPlusOneWriter() {
    Log.info("dayPlusOneWriter ::: flatFileItemWriter() :: Thread Id: {}, Thread name: {}",
            Thread.currentThread().getId(), Thread.currentThread().getName());

    String threadParam = Thread.currentThread().getId() + "-" + Thread.currentThread().getName() + "-" + new Random().nextInt();

    this.outputFlatFilePath = dynamicConfigPropRepository
            .findPropertyValueByPropertyName("collectionletters.output.flat.file.path");
    this.aggregatorFormat = dynamicConfigPropRepository
            .findPropertyValueByPropertyName("collectionletters.aggregator.format");
    this.flatfileWriterName = dynamicConfigPropRepository
            .findPropertyValueByPropertyName("collectionletters.flatfile.writer.name");

    FlatFileItemWriter<RetrievalDTO> itemWriter = new FlatFileItemWriter<>();
    itemWriter.setName(flatfileWriterName);

    String fullFilePath = outputFlatFilePath + "/" + threadParam + "dayPlusOneWriter.txt";
    itemWriter.setResource(new FileSystemResource(fullFilePath));

    // Set the header
    itemWriter.setHeaderCallback(writer -> {
        writer.write("LIST OF CREDIT ASSISTANCE PTUI CC AUTOPAY PAYMENTS THAT ARE...\n");
        writer.write("TRAN REF ID    | CC-ACCOUNT NUMBER     | PAYMENT TYPE | DUE DATE   | HANGING DAYS | MARKET ID | CREATE TIMESTAMP\n");
        writer.write("---------------------------------------------------------------------------------------------------------------\n");
    });

    // Set the footer callback to write the total record count
    itemWriter.setFooterCallback(writer -> {
        int totalRecordCount = RetrievalDTOProcessor.getTotalRecordCount(); // Get the total valid record count from the processor
        writer.write("T TOTAL RECORD COUNT " + String.format("%015d", totalRecordCount) + "\n");
        log.info("Footer added with total valid record count: {}", totalRecordCount);
    });

    // Set the LineAggregator for formatting the records
    FormatterLineAggregator<RetrievalDTO> formatterAggregator = new FormatterLineAggregator<>();
    BeanWrapperFieldExtractor<RetrievalDTO> extractor = new BeanWrapperFieldExtractor<>();
    extractor.setNames(RetrievalDTO.outputFields());
    formatterAggregator.setFieldExtractor(extractor);
    formatterAggregator.setFormat(aggregatorFormat);
    itemWriter.setLineAggregator(formatterAggregator);

    Log.info("dayPlusOneWriter ::: flatFileItemWriter() ::: writer Object ::: {}", itemWriter);

    return itemWriter;
}

  int totalRecordCount = RetrievalDTOProcessor.getTotalRecordCount(); // Get the total valid record count from the processor
        writer.write("T TOTAL RECORD COUNT " + String.format("%015d", totalRecordCount) + "\n");
        log.info("Footer added with total valid record count: {}", totalRecordCount);





import lombok.extern.log4j.Log4j2;
import org.springframework.batch.core.JobExecution;
import org.springframework.batch.core.JobExecutionListener;
import org.springframework.batch.core.configuration.annotation.StepScope;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Log4j2
@Component
public class SdpRespJobListener implements JobExecutionListener {

    @Autowired
    protected M2MDynamicConfigPropertiesRepository dynamicConfigPropertiesRepository;

    @Autowired
    private FileWriterService exceptionWriter;

    @Autowired
    private SDPExceptionHandlerService exceptionHandler;

    @Override
    public void beforeJob(JobExecution jobExecution) {
        log.trace("SdpRespJobListener ::: beforeJob ::: Entry");

        // Get ExecutionContext
        ExecutionContext context = jobExecution.getExecutionContext();

        try {
            // Example: Initialize some file properties if needed
            exceptionWriter.initFileProperties();
            exceptionWriter.writeHeader();
        } catch (IOException e) {
            log.error("SdpRespJobListener ::: beforeJob :: Exception in creating exception file", e);
            jobExecution.setExitStatus(new ExitStatus("FAILED", "Exception File Creation Issue"));
        }

        // Fetch and add necessary file paths and names for the aggregation tasklet
        String outputDirectory = dynamicConfigPropertiesRepository
                .findPropertyValueByPropertyName("collectionletters.output.flat.file.path");

        // File names for the files to aggregate
        String dayPlusOneFileName = "dayPlusOneWriter.txt";
        String moreThan7DaysFileName = "moreThan7DaysWriter.txt";
        String moreThan25DaysFileName = "moreThan25DaysWriter.txt";

        // Add properties to the ExecutionContext
        context.putString("outputDirectory", outputDirectory);
        context.putString("dayPlusOneFileName", dayPlusOneFileName);
        context.putString("moreThan7DaysFileName", moreThan7DaysFileName);
        context.putString("moreThan25DaysFileName", moreThan25DaysFileName);

        // Additional context properties as per the existing logic
        String customerType = jobExecution.getJobParameters().getString(SdpRespConstants.JOB_TYPE);
        String bacardiFilePath = dynamicConfigPropertiesRepository
                .findPropertyValueByPropertyName(SdpRespConstants.BACARDI_FILE_DIRECTORY_PATH);
        String requestFilePath = dynamicConfigPropertiesRepository
                .findPropertyValueByPropertyName(SdpRespConstants.SDP_REQUEST_FILE_DIRECTORY_PATH);
        String jobID = jobExecution.getJobId().toString();
        context.putString(SdpRespConstants.JOB_ID, jobID);
        context.putString(SdpRespConstants.BACARDI_RESPONSE_DIRECTORY_PATH, bacardiFilePath);
        context.putString(SdpRespConstants.SDP_REQUEST_DIRECTORY_PATH, requestFilePath);

        // Job-specific logic for file prefixes
        if (SdpRespConstants.CONSUMER.equalsIgnoreCase(customerType)) {
            context.putString(SdpRespConstants.BACARDI_RESPONSE_FILE_PREFIX,
                    dynamicConfigPropertiesRepository.findPropertyValueByPropertyName(SdpRespConstants.BACARDI_CONSUMER_FILE_PREFIX));
            context.putString(SdpRespConstants.SDP_REQUEST_FILE_PREFIX,
                    SdpRespConstants.CONSUMER_SDPREQUEST_FILE_PREFIX);
        } else {
            context.putString(SdpRespConstants.BACARDI_RESPONSE_FILE_PREFIX,
                    dynamicConfigPropertiesRepository.findPropertyValueByPropertyName(SdpRespConstants.BACARDI_SMB_FILE_PREFIX));
            context.putString(SdpRespConstants.SDP_REQUEST_FILE_PREFIX,
                    SdpRespConstants.SMB_SDPREQUEST_FILE_PREFIX);
        }

        log.trace("SdpRespJobListener ::: beforeJob ::: Exit");
    }

    @Override
    public void afterJob(JobExecution jobExecution) {
        log.trace("SdpRespJobListener ::: afterJob ::: Entry");

        // Check job completion status and retrieve execution context details
        if (jobExecution.getStatus() == BatchStatus.COMPLETED) {
            ExecutionContext context = jobExecution.getExecutionContext();
            int readCount = context.getInt(SdpRespConstants.READ_COUNT, 0);
            int writeCount = context.getInt(SdpRespConstants.WRITE_COUNT, 0);
            int skipCount = context.getInt(SdpRespConstants.SKIP_COUNT, 0);

            log.debug("SdpRespJobListener ::: afterJob :: Records Read: {}, Records Skipped: {}, Records Written: {}",
                    readCount, skipCount, writeCount);

            // Archive file logic or unlock file, if needed
            String filePrefix = jobExecution.getExecutionContext().getString(SdpRespConstants.BACARDI_RESPONSE_FILE_PREFIX);
            String directoryPath = jobExecution.getExecutionContext().getString(SdpRespConstants.BACARDI_RESPONSE_DIRECTORY_PATH);
            LocalDate date = LocalDate.now();
            if (date.getDayOfWeek().equals(DayOfWeek.MONDAY)) {
                date = date.minusDays(1);
            }

            FileUtils.unlockFile(directoryPath, filePrefix, SdpRespConstants.LOCK_FILE_EXTENSION, date);
            FileUtils.archiveFile(directoryPath, filePrefix, SdpRespConstants.INPUT_FILE_EXTENSION, date);

        } else {
            // Error handling if the job fails
            log.error("SdpRespJobListener ::: afterJob :: Job failed with status: {}", jobExecution.getStatus());
        }

        log.trace("SdpRespJobListener ::: afterJob ::: Exit");
    }
}
